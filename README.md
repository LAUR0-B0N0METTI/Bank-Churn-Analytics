```markdown
# ğŸ¦ Bank Churn Analytics Pro - DocumentaÃ§Ã£o TÃ©cnica

![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=TensorFlow&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)

---

## ğŸ“Œ VisÃ£o Geral do Projeto

**Bank Churn Analytics Pro** Ã© uma soluÃ§Ã£o de machine learning voltada Ã  prediÃ§Ã£o de rotatividade de clientes bancÃ¡rios. O sistema combina modelos tradicionais (Random Forest) com redes neurais profundas para obter alta acurÃ¡cia e insights interpretÃ¡veis.

### ğŸ¯ Objetivo Principal
Reduzir a taxa de cancelamento de clientes por meio de:
- IdentificaÃ§Ã£o antecipada de clientes propensos ao churn
- AnÃ¡lise de padrÃµes comportamentais crÃ­ticos
- SugestÃ£o de aÃ§Ãµes personalizadas de retenÃ§Ã£o

---

## ğŸš€ Principais Funcionalidades

| MÃ³dulo                  | Tecnologias                 | Finalidade                               |
|------------------------|-----------------------------|------------------------------------------|
| **AnÃ¡lise Preditiva**  | Random Forest, TensorFlow   | Estimar a probabilidade de churn         |
| **Dashboard Interativo** | Streamlit, Plotly           | VisualizaÃ§Ã£o em tempo real dos insights |
| **ETL Automatizado**   | Pandas, Scikit-learn         | Limpeza e transformaÃ§Ã£o dos dados        |
| **GestÃ£o de Modelos**  | Joblib, Keras                | Versionamento e deploy de modelos        |

---

## ğŸ“‚ Dataset e Origem dos Dados

### ğŸ“ Fonte Original
O conjunto de dados utilizado Ã© o [**Bank Customer Churn Dataset**](https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction), amplamente adotado em projetos de ML voltados para churn.

### ğŸ§¾ Principais CaracterÃ­sticas

| Feature      | Tipo       | DescriÃ§Ã£o                              | TransformaÃ§Ã£o Aplicada          |
|--------------|------------|----------------------------------------|---------------------------------|
| `CreditScore`| NumÃ©rico   | PontuaÃ§Ã£o de crÃ©dito (300â€“850)         | NormalizaÃ§Ã£o z-score            |
| `Geography`  | CategÃ³rico | PaÃ­s do cliente                        | One-Hot Encoding                |
| `Age`        | NumÃ©rico   | Idade do cliente                       | Binning estratificado           |
| `Balance`    | NumÃ©rico   | Saldo mÃ©dio anual                      | Log-transform                   |
| `Exited`     | BinÃ¡rio    | Indicador de churn (0 = NÃ£o, 1 = Sim)  | Balanceamento via SMOTE         |

### ğŸ”„ Exemplo de PrÃ©-processamento
```python
import pandas as pd

df = pd.read_csv('Churn_Modelling.csv')
df = df.rename(columns={'Exited': 'Churn'})
df['Geography'] = df['Geography'].str.title()
```

---

## ğŸ§  Arquitetura do Sistema

```mermaid
graph TD
    A[Coleta de Dados] --> B[PrÃ©-processamento]
    B --> C[Treinamento de Modelos]
    C --> D[ValidaÃ§Ã£o Cruzada]
    D --> E[Interface Streamlit]
    E --> F[VisualizaÃ§Ã£o Interativa]
```

---

## ğŸ” DecisÃµes EstratÃ©gicas

### ğŸ“š Bibliotecas e Justificativas

| Biblioteca          | Caso de Uso                          | Vantagem TÃ©cnica                               |
|---------------------|--------------------------------------|------------------------------------------------|
| **Scikit-learn**    | PrÃ©-processamento                    | Pipelines robustos e integraÃ§Ã£o com Pandas     |
| **TensorFlow/Keras**| Modelagem profunda                   | Arquitetura flexÃ­vel para padrÃµes nÃ£o-lineares |
| **Random Forest**   | Modelo baseline interpretÃ¡vel        | AnÃ¡lise de importÃ¢ncia de variÃ¡veis            |
| **Imbalanced-learn**| Dados desbalanceados                 | SMOTE para melhorar recall                     |

---

### ğŸ”€ EstratÃ©gia de Modelagem HÃ­brida

```python
# Rede Neural Profunda (Keras)
model = Sequential([
    Dense(128, activation='relu', input_shape=(input_dim,)),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Random Forest Otimizado
rf_model = RandomForestClassifier(
    n_estimators=200,
    max_depth=10,
    class_weight='balanced'
)
```

**âœ”ï¸ BenefÃ­cios da Abordagem Combinada:**
- Balanceia interpretabilidade e performance
- RedundÃ¢ncia para validaÃ§Ã£o cruzada
- Aumenta robustez contra overfitting

---

## ğŸ“Š Pipeline de Treinamento

### 1ï¸âƒ£ PrÃ©-processamento
```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ]
)
```

**Etapas-Chave:**
- NormalizaÃ§Ã£o z-score
- One-Hot robusto com `handle_unknown='ignore'`
- Amostragem estratificada por classe alvo

### 2ï¸âƒ£ AvaliaÃ§Ã£o de Modelos

| MÃ©trica   | Random Forest | Neural Network |
|-----------|---------------|----------------|
| AcurÃ¡cia  | 87.3%         | 89.1%          |
| PrecisÃ£o  | 83.5%         | 85.2%          |
| Recall    | 78.9%         | 82.4%          |
| AUC-ROC   | 0.91          | 0.93           |

### 3ï¸âƒ£ TÃ©cnicas Contra Overfitting
- **Random Forest**: `max_depth=10`, `class_weight='balanced'`
- **Neural Network**: Dropout, Early Stopping
- ValidaÃ§Ã£o cruzada estratificada (5 folds)

---

## ğŸ› ï¸ Guia de ImplementaÃ§Ã£o

### ğŸ’» Requisitos MÃ­nimos
- CPU: 4 nÃºcleos (Intel i5 ou superior)
- RAM: 8GB+
- Armazenamento: 1GB disponÃ­vel

### âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

```bash
# Clone do repositÃ³rio
git clone https://github.com/seu-usuario/bank-churn-analytics.git

# Ambiente virtual (recomendado)
python -m venv .venv
source .venv/bin/activate      # Linux/Mac
.\.venv\Scripts\activate       # Windows

# InstalaÃ§Ã£o das dependÃªncias
pip install -r requirements.txt

# Executar o sistema
streamlit run app.py
```

---

## ğŸŒ Roadmap de EvoluÃ§Ã£o

### ğŸ”œ Fase 2 â€“ Q3 2024
- IntegraÃ§Ã£o com APIs bancÃ¡rias
- Sistema de recomendaÃ§Ãµes de retenÃ§Ã£o
- Monitoramento contÃ­nuo de desempenho

### ğŸš€ Fase 3 â€“ Q4 2024
- Modelos Transformers (BERT) para feedbacks textuais
- AutoML para tuning de hiperparÃ¢metros
- Dashboard executivo com KPIs de churn

---

## ğŸ“š ReferÃªncias TÃ©cnicas
- [Scikit-learn: Ensemble Methods](https://scikit-learn.org/stable/modules/ensemble.html)
- [TensorFlow: Saving and Loading Models](https://www.tensorflow.org/guide/keras/serialization_and_saving)
- [Imbalanced-learn Documentation](https://imbalanced-learn.org/stable/)

---

**ğŸ‘¨â€ğŸ’» Autor:** Lauro Bonometti  
**ğŸ“„ LicenÃ§a:** MIT  
**ğŸ“¬ Contato:** lauro.f.bonometti@gmail.com
```
